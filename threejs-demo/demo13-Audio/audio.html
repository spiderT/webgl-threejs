<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>three.js</title>
  <style>
    body {
      margin: 0;
      overflow: hidden;
    }
  </style>

</head>

<body>
  <script src="../three.min.js"></script>
  <script>
    // 创建场景对象Scene
    const scene = new THREE.Scene();

    // 声明一个分析器变量
    let analyser = null;

    /**
     * 创建多个网格模型组成的组对象
     */
    const group = new THREE.Group();
    let N = 128; //控制音频分析器返回频率数据数量
    for (let i = 0; i < N / 2; i++) {
      const box = new THREE.BoxGeometry(10, 100, 10); //创建一个立方体几何对象
      const material = new THREE.MeshPhongMaterial({
        color: 0x0000ff
      }); //材质对象
      const mesh = new THREE.Mesh(box, material); //网格模型对象
      // 长方体间隔20，整体居中
      mesh.position.set(20 * i - N / 2 * 10, 0, 0)
      group.add(mesh)
    }
    scene.add(group)



    // 光源设置
    //点光源
    const point = new THREE.PointLight(0xffffff);
    point.position.set(400, 200, 300); //点光源位置
    scene.add(point); //点光源添加到场景中

    //环境光
    const ambient = new THREE.AmbientLight(0x444444);
    scene.add(ambient);

    // 相机设置
    const width = window.innerWidth; //窗口宽度
    const height = window.innerHeight; //窗口高度
    const k = width / height; //窗口宽高比
    const s = 200; //三维场景显示范围控制系数，系数越大，显示的范围越大

    //创建相机对象
    const camera = new THREE.OrthographicCamera(-s * k, s * k, s, -s, 1, 1000);
    camera.position.set(0, 300, 300); //设置相机位置
    camera.lookAt(scene.position); //设置相机方向(指向的场景对象

    // 创建渲染器对象
    const renderer = new THREE.WebGLRenderer();
    renderer.setSize(width, height); //设置渲染区域尺寸
    renderer.setClearColor(0xb9d3ff, 1); //设置背景颜色
    document.body.appendChild(renderer.domElement); //body元素中插入canvas对象


    // 渲染函数
    function render() {
      renderer.render(scene, camera); //执行渲染操作
      requestAnimationFrame(render); //请求再次执行渲染函数render，渲染下一帧
      if (analyser) {
        // 获得频率数据N个
        const arr = analyser.getFrequencyData();
        // console.log(arr);
        // 遍历组对象，每个网格子对象设置一个对应的频率数据
        group.children.forEach((elem, index) => {
          elem.scale.y = arr[index] / 80
          elem.material.color.r = arr[index] / 200;
        });
      }
    }

    const listener = new THREE.AudioListener() //监听者
    const audio = new THREE.Audio(listener); //非位置音频对象
    const audioLoader = new THREE.AudioLoader(); //音频加载器
    // 加载音频文件
    audioLoader.load('./wavefile_short.mp3', function (AudioBuffer) {
      audio.setBuffer(AudioBuffer); // 音频缓冲区对象关联到音频对象audio
      audio.setLoop(true); //是否循环
      audio.setVolume(1); //音量
      audio.play(); //播放
      // 音频分析器和音频绑定，可以实时采集音频时域数据进行快速傅里叶变换
      analyser = new THREE.AudioAnalyser(audio, 2 * N);
    });


    render();
  </script>
</body>

</html>